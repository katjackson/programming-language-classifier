{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline, make_union, FeatureUnion\n",
    "from sklearn.preprocessing import PolynomialFeatures, normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in Data\n",
    "Used glob to read a bunch of files with a similar path according to file extension. This allowed me to get just the languages I wanted in my data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_prog_files(file_ext):\n",
    "    files = glob.glob('/Users/kathrynjackson/Code/homework/programming-language-classifier/benchmarksgame-2014-08-31/benchmarksgame/bench/**/*.{}'.format(file_ext), recursive=True)\n",
    "    texts = []\n",
    "    for file in files:\n",
    "        with open(file) as f:\n",
    "            texts.append(f.read())\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in each type of file and concatenated data into x and y lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "552 552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_extensions = ['gcc', 'c', 'csharp', 'sbcl', 'clojure', 'java', 'javascript', 'ocaml', 'perl', 'hack', 'php', 'python3', 'jruby', 'yarv', 'scala', 'racket']\n",
    "ext_dict = {'jruby': 'ruby', 'csharp': 'c#', 'hack': 'php', 'sbcl': 'common lisp', 'ocaml': 'ocaml', 'python3': 'python', 'php': 'php', 'perl': 'perl', 'racket': 'scheme', 'c': 'c', 'javascript': 'javascript', 'gcc': 'c', 'yarv': 'ruby', 'java': 'java', 'clojure': 'clojure', 'scala': 'scala'}\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for ext in file_extensions:\n",
    "    x_texts = read_prog_files(ext)\n",
    "    X += x_texts\n",
    "    y += (len(x_texts) * [ext_dict[ext]])\n",
    "    \n",
    "print(len(X), len(y))\n",
    "len(set(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "Used the train_test_split method from sklearn to split data set into 60/40 for training and testing the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, train_size=0.6, random_state=890)\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to includ the one '.c' file in my training data, not my test data, so I made sure the length of my training data was 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction: Count Vectorizer\n",
    "I used scikit-learn's count vectorizer to extract features from the data. I wanted words, white spaces, and puctuaion, but not numbers, which I assumed would be less language specific and more project specific. There are a lot of features in this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5857\n",
      "[\"!='\\\\\", '!=(', '!==', '!}', '!~', '\"', '\"\"', '\"\"\"', '\"\"\".', '\"\"\";', '\"\"\">.*\\\\', '\"\")', '\"\"))', '\"\")))', '\"\");', '\"\",', '\"\".', '\"\";', '\"#{', '\"#{$']\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(token_pattern=r'[a-zA-Z]{2,}|[^\\w\\d\\s]+')\n",
    "cv.fit(X_train)\n",
    "cv.transform(X_train)\n",
    "print(len(cv.get_feature_names()))\n",
    "print(cv.get_feature_names()[20:40])\n",
    "# cv.vocabulary_\n",
    "# tuple_list = [(best_dict[key], key) for key in best_dict]\n",
    "# sorted(tuple_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92760180995475117"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baye_pipe = Pipeline([('vectorizer', CountVectorizer(token_pattern=r'[a-zA-Z]{2,}|\\s|[^\\w\\d\\s]')),\n",
    "                      ('classifier', MultinomialNB())])\n",
    "\n",
    "baye_pipe.fit(X_train, y_train)\n",
    "baye_pipe.named_steps['vectorizer'].transform(X_train)\n",
    "\n",
    "baye_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.968325791855\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_pipe = Pipeline([('vectorizer', CountVectorizer(token_pattern=r'[a-zA-Z]{2,}|\\s|[^\\w\\d\\s]')),\n",
    "#                       ('transformer', TfidfTransformer()),\n",
    "                      ('classifier', DecisionTreeClassifier())])\n",
    "\n",
    "tree_pipe.fit(X_train, y_train)\n",
    "tree_pipe.named_steps['vectorizer'].transform(X_train)\n",
    "\n",
    "print(tree_pipe.score(X_train, y_train))\n",
    "print(tree_pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "This meta estimator performs worse than the single decision tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.981900452489\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_pipe = Pipeline([('vectorizer', CountVectorizer(token_pattern=r'[a-zA-Z]{2,}|\\s|[^\\w\\d\\s]')),\n",
    "#                       ('transformer', TfidfTransformer()),\n",
    "                        ('classifier', RandomForestClassifier())])\n",
    "\n",
    "forest_pipe.fit(X_train, y_train)\n",
    "forest_pipe.named_steps['vectorizer'].transform(X_train)\n",
    "\n",
    "print(forest_pipe.score(X_train, y_train))\n",
    "print(forest_pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_test_files():\n",
    "    files = glob.glob('/Users/kathrynjackson/Code/homework/assignments-master/week5/polyglot/test/*', recursive=True)\n",
    "    tests = []\n",
    "    for file in files:\n",
    "        with open(file) as f:\n",
    "            tests.append(f.read())\n",
    "    return tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "testy_X = read_test_files()\n",
    "testy_y = []\n",
    "with open('/Users/kathrynjackson/Code/homework/assignments-master/week5/polyglot/test.csv') as test_targets:\n",
    "    lines = csv.reader(test_targets)\n",
    "    for line in lines:\n",
    "        testy_y.append(line[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03125\n",
      "['python' 'ocaml' 'javascript' 'javascript' 'ruby' 'ocaml' 'c' 'python'\n",
      " 'python' 'python' 'ocaml' 'ocaml' 'ocaml' 'ocaml' 'java' 'javascript'\n",
      " 'scala' 'scala' 'ocaml' 'python' 'php' 'ocaml' 'ocaml' 'php' 'python'\n",
      " 'ocaml' 'python' 'python' 'python' 'python' 'python' 'javascript']\n"
     ]
    }
   ],
   "source": [
    "print(tree_pipe.score(testy_X, testy_y))\n",
    "print(tree_pipe.predict(testy_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03125\n",
      "['ocaml' 'ruby' 'ocaml' 'javascript' 'ruby' 'ruby' 'ruby' 'ruby' 'ruby'\n",
      " 'ruby' 'ocaml' 'php' 'ruby' 'scheme' 'perl' 'ruby' 'python' 'c#' 'ruby'\n",
      " 'perl' 'php' 'perl' 'ruby' 'ocaml' 'ocaml' 'c' 'c' 'python' 'python'\n",
      " 'perl' 'python' 'javascript']\n"
     ]
    }
   ],
   "source": [
    "print(forest_pipe.score(testy_X, testy_y))\n",
    "print(forest_pipe.predict(testy_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03125\n",
      "['clojure' 'javascript' 'scala' 'scala' 'ruby' 'ruby' 'ruby' 'java' 'scala'\n",
      " 'scala' 'scheme' 'clojure' 'scheme' 'scheme' 'c' 'c' 'scala' 'scala' 'php'\n",
      " 'php' 'c' 'php' 'clojure' 'php' 'ocaml' 'ocaml' 'java' 'python' 'python'\n",
      " 'python' 'python' 'javascript']\n"
     ]
    }
   ],
   "source": [
    "print(baye_pipe.score(testy_X, testy_y))\n",
    "print(baye_pipe.predict(testy_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clojure',\n",
       " 'clojure',\n",
       " 'clojure',\n",
       " 'clojure',\n",
       " 'python',\n",
       " 'python',\n",
       " 'python',\n",
       " 'python',\n",
       " 'javascript',\n",
       " 'javascript',\n",
       " 'javascript',\n",
       " 'javascript',\n",
       " 'ruby',\n",
       " 'ruby',\n",
       " 'ruby',\n",
       " 'haskell',\n",
       " 'haskell',\n",
       " 'haskell',\n",
       " 'scheme',\n",
       " 'scheme',\n",
       " 'scheme',\n",
       " 'java',\n",
       " 'java',\n",
       " 'scala',\n",
       " 'scala',\n",
       " 'tcl',\n",
       " 'tcl',\n",
       " 'php',\n",
       " 'php',\n",
       " 'php',\n",
       " 'ocaml',\n",
       " 'ocaml']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Your Own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "def caps_to_non(text):\n",
    "    cap_letters = re.findall(r'[A-Z]', text)\n",
    "    non_caps = re.findall(r'[a-z]', text)\n",
    "    return len(cap_letters) / len(non_caps)\n",
    "    \n",
    "    \n",
    "#                                 percent_occurence_of_parenthesis,\n",
    "#                                 percent_occurence_of_curly,\n",
    "#                                 percent_occurence_of_space,\n",
    "\n",
    "# def next_to_last_character(text):\n",
    "#     return text[-2]\n",
    "\n",
    "def percent_occurence_of_parenthesis(text):\n",
    "    pars = re.findall(r'\\(|\\)', text)\n",
    "    return len(pars) / len(text)\n",
    "\n",
    "def percent_occurence_of_curly(text):\n",
    "    curls = re.findall(r'\\{|\\}', text)\n",
    "    return len(curls) / len(text)\n",
    "\n",
    "def percent_occurence_of_space(text):\n",
    "    spaces = re.findall(r'\\s', text)\n",
    "    return len(spaces) / len(text)\n",
    "\n",
    "\n",
    "def has_end(text):\n",
    "    if re.search(r'end', text):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def occurence_of_this_pattern(reg_ex):\n",
    "    \n",
    "    def feature_fn(text):\n",
    "        occ = re.findall(r'{}'.format(reg_ex), text)\n",
    "        return len(occ)\n",
    "\n",
    "    return feature_fn\n",
    "\n",
    "\n",
    "class FunctionFeaturizer(TransformerMixin):\n",
    "    def __init__(self, *featurizers):\n",
    "        self.featurizers = featurizers\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        fvs = []\n",
    "        for text in X:\n",
    "            fv = [f(text) for f in self.featurizers]\n",
    "            fvs.append(fv)\n",
    "        return np.array(fvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bag_plus_featurizer = make_union(\n",
    "#     CountVectorizer(token_pattern=r'[a-zA-Z]{2,}|\\s|[^\\w\\d\\s]'),\n",
    "#     FunctionFeaturizer(number_of_capital_letters,\n",
    "#                                 occurence_of_parenthesis,\n",
    "#                                 occurence_of_curly,\n",
    "#                                 occurence_of_space,\n",
    "#                                 occurence_of_s_function,\n",
    "#                                 occurence_of_punctuation,\n",
    "#                                 new_line_per_char))\n",
    "\n",
    "# bag_plus_featurizer.fit_transform(X[:10])\n",
    "# baggy_pipe = Pipeline([('my_featurizer', bag_plus_featurizer()),\n",
    "#                         ('my classifier', DecisionTreeClassifier())])\n",
    "# baggy_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for text in X_train:\n",
    "#     print(percent_occurence_of_punctuation(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kathrynjackson/Code/homework/.direnv/python-3.5.1/lib/python3.5/site-packages/sklearn/utils/__init__.py:93: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.941176470588\n",
      "0.125\n",
      "['clojure' 'javascript' 'ocaml' 'javascript' 'ruby' 'ruby' 'ruby' 'ocaml'\n",
      " 'javascript' 'ocaml' 'javascript' 'javascript' 'javascript' 'php' 'java'\n",
      " 'scala' 'php' 'scala' 'php' 'php' 'java' 'php' 'javascript' 'php' 'ocaml'\n",
      " 'ocaml' 'clojure' 'javascript' 'scala' 'scala' 'scala' 'javascript']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kathrynjackson/Code/homework/.direnv/python-3.5.1/lib/python3.5/site-packages/sklearn/utils/__init__.py:93: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/kathrynjackson/Code/homework/.direnv/python-3.5.1/lib/python3.5/site-packages/sklearn/utils/__init__.py:93: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/kathrynjackson/Code/homework/.direnv/python-3.5.1/lib/python3.5/site-packages/sklearn/utils/__init__.py:93: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import binarize\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "featurizer = FunctionFeaturizer(caps_to_non,\n",
    "                                percent_occurence_of_parenthesis,\n",
    "                                percent_occurence_of_curly,\n",
    "                                percent_occurence_of_space,\n",
    "                                occurence_of_this_pattern('&\\w'),\n",
    "                                occurence_of_this_pattern('\\$\\w'),\n",
    "                                occurence_of_this_pattern('[A-Za-z]+[A-Z]'))\n",
    "\n",
    "# my_vocab = ['function', '{', '}', '\\n', '\\t', ':', ';', 'def', ',', '->',\n",
    "#             '(', ')', 'call', 'lambda', 'set', '@', '>', '<', '.', '[',\n",
    "#             ']', 'var', 'elif', 'else', 'else if', 'then', 'in',\n",
    "#             'switch', 'IfTrue', 'IfFalse', 'unless', 'not', 'elsif',\n",
    "#             'given', 'end', 'match', '(if', '(otherwise', 'progn', 'begin',\n",
    "#             'cond', 'then begin', 'with', 'when', 'foreach', 'for each',\n",
    "#             'for_each', 'for (', '$i++', '$i', '$', 'do', 'until', 'loop',\n",
    "#             'let loop', 'for-each', 'done', '.iter', 'catch', 'except',\n",
    "#             'longjmp', 'setjmp', 'finally', 'throw', 'die', 'eval', '$@',\n",
    "#             'rescue', 'ensure', 'handler-', 'check-', 'guard', 'try:',\n",
    "#             'catchError', 'last', 'break', 'return-from',\n",
    "#             'loop-finish', 'go', 'goto', 'next', 'func', 'void', 'int main',\n",
    "#             'main', 'public', 'defun', 'setf', 'define', '&', '*', '/',\n",
    "#             'require', ' = ', 'import', '__init__']\n",
    "# cv = CountVectorizer(vocabulary=my_vocab)\n",
    "\n",
    "cv = CountVectorizer(token_pattern=r'[a-zA-Z]{2,}|\\s|[^\\w\\d\\s]', lowercase=False)\n",
    "# cv = CountVectorizer(token_pattern=r'[a-zA-Z]{2,}|[^\\w\\d\\s]+')\n",
    "\n",
    "# cv = CountVectorizer(analyzer='char', ngram_range=(2,3))\n",
    "\n",
    "# cv = CountVectorizer(lowercase=False)\n",
    "\n",
    "feature_extractors = FeatureUnion([('my featurizer', featurizer), ('cv', cv)])\n",
    "\n",
    "spca = PCA()\n",
    "\n",
    "\n",
    "foresty = Pipeline([\n",
    "                    ('featurizer', feature_extractors),\n",
    "#                     ('transformer', TfidfTransformer()),\n",
    "                    ('classifier', DecisionTreeClassifier()),\n",
    "                    ('linsvc', LinearSVC()),\n",
    "                    ])\n",
    "\n",
    "foresty.fit(X_train, y_train)\n",
    "foresty.named_steps['featurizer'].transform(X_train)\n",
    "print(foresty.score(X_test, y_test))\n",
    "\n",
    "print(foresty.score(testy_X, testy_y))\n",
    "print(foresty.predict(testy_X))\n",
    "\n",
    "\n",
    "# featurizer.fit(X_train)\n",
    "# featurizer.transform(X_train)\n",
    "# tree = DecisionTreeClassifier()\n",
    "# tree.fit(featurizer.transform(X_train), y_train)\n",
    "# tree.score(featurizer.transform(X_test), y_test)\n",
    "# tree.predict(featurizer.transform(testy_X), testy_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a_tree_pipe.predict(testy_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clojure', 'clojure', 'clojure', 'clojure', 'python', 'python', 'python', 'python', 'javascript', 'javascript', 'javascript', 'javascript', 'ruby', 'ruby', 'ruby', 'haskell', 'haskell', 'haskell', 'scheme', 'scheme', 'scheme', 'java', 'java', 'scala', 'scala', 'tcl', 'tcl', 'php', 'php', 'php', 'ocaml', 'ocaml']\n"
     ]
    }
   ],
   "source": [
    "print(testy_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-306-4794128bd099>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-306-4794128bd099>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    return [do something for t in other tokenizer(text)]\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class MyTokenizer():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, text):\n",
    "        return [do something for t in other tokenizer(text)]\n",
    "    \n",
    "vect = CountVectorizer(tokenizer=MyTokenizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\t': 4,\n",
       " '\\n': 3,\n",
       " ' = ': 94,\n",
       " '$': 51,\n",
       " '$@': 67,\n",
       " '$i': 50,\n",
       " '$i++': 49,\n",
       " '&': 90,\n",
       " '(': 10,\n",
       " '(if': 37,\n",
       " '(otherwise': 38,\n",
       " ')': 11,\n",
       " '*': 91,\n",
       " ',': 8,\n",
       " '--': 95,\n",
       " '->': 9,\n",
       " '.': 18,\n",
       " '.iter': 58,\n",
       " '/': 92,\n",
       " ':': 5,\n",
       " ';': 6,\n",
       " '<': 17,\n",
       " '>': 16,\n",
       " '@': 15,\n",
       " 'IfFalse': 30,\n",
       " 'IfTrue': 29,\n",
       " '[': 19,\n",
       " ']': 20,\n",
       " 'begin': 40,\n",
       " 'break': 76,\n",
       " 'call': 12,\n",
       " 'catch': 59,\n",
       " 'catchError': 74,\n",
       " 'check-': 71,\n",
       " 'cond': 41,\n",
       " 'def ': 7,\n",
       " 'define': 89,\n",
       " 'defun': 87,\n",
       " 'die': 65,\n",
       " 'do': 52,\n",
       " 'done': 57,\n",
       " 'elif': 23,\n",
       " 'else': 24,\n",
       " 'else if': 25,\n",
       " 'elsif': 33,\n",
       " 'end': 35,\n",
       " 'ensure': 69,\n",
       " 'eval': 66,\n",
       " 'except': 60,\n",
       " 'finally': 63,\n",
       " 'for (': 48,\n",
       " 'for each': 46,\n",
       " 'for-each': 56,\n",
       " 'for_each': 47,\n",
       " 'foreach': 45,\n",
       " 'func': 82,\n",
       " 'function': 0,\n",
       " 'given': 34,\n",
       " 'go': 79,\n",
       " 'goto': 80,\n",
       " 'guard': 72,\n",
       " 'handler-': 70,\n",
       " 'if': 22,\n",
       " 'in': 27,\n",
       " 'int main': 84,\n",
       " 'lambda': 13,\n",
       " 'last': 75,\n",
       " 'let loop': 55,\n",
       " 'longjmp': 61,\n",
       " 'loop': 54,\n",
       " 'loop-finish': 78,\n",
       " 'main': 85,\n",
       " 'match': 36,\n",
       " 'next': 81,\n",
       " 'not': 32,\n",
       " 'progn': 39,\n",
       " 'public': 86,\n",
       " 'require': 93,\n",
       " 'rescue': 68,\n",
       " 'return-from': 77,\n",
       " 'set': 14,\n",
       " 'setf': 88,\n",
       " 'setjmp': 62,\n",
       " 'switch': 28,\n",
       " 'then': 26,\n",
       " 'then begin': 42,\n",
       " 'throw': 64,\n",
       " 'try:': 73,\n",
       " 'unless': 31,\n",
       " 'until': 53,\n",
       " 'var': 21,\n",
       " 'void': 83,\n",
       " 'when': 44,\n",
       " 'with': 43,\n",
       " '{': 1,\n",
       " '}': 2}"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_vocab = ['function', '{', '}', '\\n', '\\t', ':', ';', 'def ', ',', '->',\n",
    "            '(', ')', 'call', 'lambda', 'set', '@', '>', '<', '.', '[',\n",
    "            ']', 'var', 'if', 'elif', 'else', 'else if', 'then', 'in',\n",
    "            'switch', 'IfTrue', 'IfFalse', 'unless', 'not', 'elsif',\n",
    "            'given', 'end', 'match', '(if', '(otherwise', 'progn', 'begin',\n",
    "            'cond', 'then begin', 'with', 'when', 'foreach', 'for each',\n",
    "            'for_each', 'for (', '$i++', '$i', '$', 'do', 'until', 'loop',\n",
    "            'let loop', 'for-each', 'done', '.iter', 'catch', 'except',\n",
    "            'longjmp', 'setjmp', 'finally', 'throw', 'die', 'eval', '$@',\n",
    "            'rescue', 'ensure', 'handler-', 'check-', 'guard', 'try:',\n",
    "            'catchError', 'last', 'break', 'return-from',\n",
    "            'loop-finish', 'go', 'goto', 'next', 'func', 'void', 'int main',\n",
    "            'main', 'public', 'defun', 'setf', 'define', '&', '*', '/',\n",
    "            'require', ' = ', '--']\n",
    "cv = CountVectorizer(vocabulary=my_vocab)\n",
    "\n",
    "cv.fit(X_train)\n",
    "cv.transform(X_train)\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.918552036199\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_pipe = Pipeline([('vectorizer', CountVectorizer(vocabulary=my_vocab)),\n",
    "                      ('transformer', TfidfTransformer()),\n",
    "                        ('classifier', RandomForestClassifier())])\n",
    "\n",
    "forest_pipe.fit(X_train, y_train)\n",
    "forest_pipe.named_steps['vectorizer'].transform(X_train)\n",
    "\n",
    "print(forest_pipe.score(X_train, y_train))\n",
    "print(forest_pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And now for something completely different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = ['/Users/kathrynjackson/Code/homework/programming-language-classifier/benchmarksgame-2014-08-31/benchmarksgame/bench/binarytrees/binarytrees.gcc',\n",
    "            '/Users/kathrynjackson/Code/homework/programming-language-classifier/benchmarksgame-2014-08-31/benchmarksgame/bench/binarytrees/binarytrees.gcc-2.gcc',\n",
    "            '/Users/kathrynjackson/Code/homework/programming-language-classifier/benchmarksgame-2014-08-31/benchmarksgame/bench/binarytrees/binarytrees.jruby',\n",
    "            '/Users/kathrynjackson/Code/homework/programming-language-classifier/benchmarksgame-2014-08-31/benchmarksgame/bench/binarytrees/binarytrees.jruby-3.jruby',\n",
    "            '/Users/kathrynjackson/Code/homework/programming-language-classifier/benchmarksgame-2014-08-31/benchmarksgame/bench/binarytrees/binarytrees.clojure']\n",
    "\n",
    "vectorizer = CountVectorizer(input='filename', token_pattern=r'[a-zA-Z]{2,}|[^\\w\\d\\s]')\n",
    "\n",
    "dtm = vectorizer.fit_transform(filenames)  # a sparse matrix\n",
    "\n",
    "vocab = vectorizer.get_feature_names()  # a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtm.toarray()\n",
    "vocab = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par_idx = list(vocab).index('(')\n",
    "dtm[4, par_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

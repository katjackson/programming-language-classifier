{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import csv\n",
    "import re\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in Data\n",
    "Used glob to read a bunch of files with a similar path according to file extension. This allowed me to get just the languages I wanted in my data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_prog_files(loc):\n",
    "    files = glob.glob(loc, recursive=True)\n",
    "    texts = []\n",
    "    for file in files:\n",
    "        with open(file) as f:\n",
    "            texts.append(f.read())\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in each type of file and concatenated data into x and y lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "552 552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_extensions = ['gcc', 'c', 'csharp', 'sbcl', 'clojure', 'java', 'javascript', 'ocaml', 'perl', 'hack', 'php', 'python3', 'jruby', 'yarv', 'scala', 'racket']\n",
    "ext_dict = {'jruby': 'ruby', 'csharp': 'c#', 'hack': 'php', 'sbcl': 'common lisp', 'ocaml': 'ocaml', 'python3': 'python', 'php': 'php', 'perl': 'perl', 'racket': 'scheme', 'c': 'c', 'javascript': 'javascript', 'gcc': 'c', 'yarv': 'ruby', 'java': 'java', 'clojure': 'clojure', 'scala': 'scala'}\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for ext in file_extensions:\n",
    "    x_texts = read_prog_files('/Users/kathrynjackson/Code/homework/programming-language-classifier/benchmarksgame-2014-08-31/benchmarksgame/bench/**/*.{}'.format(ext))\n",
    "    X += x_texts\n",
    "    y += (len(x_texts) * [ext_dict[ext]])\n",
    "    \n",
    "print(len(X), len(y))\n",
    "len(set(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "Used the train_test_split method from sklearn to split data set into 60/40 for training and testing the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, train_size=0.6, random_state=890)\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to includ the one '.c' file in my training data, not my test data, so I made sure the length of my training data was 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction: Count Vectorizer\n",
    "I used scikit-learn's count vectorizer to extract features from the data. I wanted words, white spaces, and puctuaion, but not numbers, which I assumed would be less language specific and more project specific. There are a lot of features in this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5860\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(token_pattern=r'[a-zA-Z]{2,}|\\s|[^\\w\\d\\s]+')\n",
    "cv.fit(X_train)\n",
    "cv.transform(X_train)\n",
    "print(len(cv.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92760180995475117"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baye_pipe = Pipeline([('vectorizer', CountVectorizer(token_pattern=r'[a-zA-Z]{2,}|\\s|[^\\w\\d\\s]')),\n",
    "                      ('classifier', MultinomialNB())])\n",
    "\n",
    "baye_pipe.fit(X_train, y_train)\n",
    "baye_pipe.named_steps['vectorizer'].transform(X_train)\n",
    "\n",
    "baye_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.93665158371\n"
     ]
    }
   ],
   "source": [
    "tree_pipe = Pipeline([('vectorizer', CountVectorizer(token_pattern=r'[a-zA-Z]{2,}|\\s|[^\\w\\d\\s]')),\n",
    "                      ('transformer', TfidfTransformer()),\n",
    "                      ('classifier', DecisionTreeClassifier())])\n",
    "\n",
    "tree_pipe.fit(X_train, y_train)\n",
    "tree_pipe.named_steps['vectorizer'].transform(X_train)\n",
    "\n",
    "print(tree_pipe.score(X_train, y_train))\n",
    "print(tree_pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "This meta estimator performs worse than the single decision tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.963800904977\n"
     ]
    }
   ],
   "source": [
    "forest_pipe = Pipeline([('vectorizer', CountVectorizer(token_pattern=r'[a-zA-Z]{2,}|\\s|[^\\w\\d\\s]')),\n",
    "#                       ('transformer', TfidfTransformer()),\n",
    "                        ('classifier', RandomForestClassifier())])\n",
    "\n",
    "forest_pipe.fit(X_train, y_train)\n",
    "forest_pipe.named_steps['vectorizer'].transform(X_train)\n",
    "\n",
    "print(forest_pipe.score(X_train, y_train))\n",
    "print(forest_pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "I read in the test files using the same function used earlier. All three classifiers performed poorly on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testy_X = read_prog_files('/Users/kathrynjackson/Code/homework/assignments-master/week5/polyglot/test/*')\n",
    "testy_y = []\n",
    "with open('/Users/kathrynjackson/Code/homework/assignments-master/week5/polyglot/test.csv') as test_targets:\n",
    "    lines = csv.reader(test_targets)\n",
    "    for line in lines:\n",
    "        testy_y.append(line[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03125\n",
      "['common lisp' 'javascript' 'javascript' 'javascript' 'ruby' 'ruby' 'ruby'\n",
      " 'java' 'javascript' 'php' 'common lisp' 'common lisp' 'common lisp'\n",
      " 'common lisp' 'java' 'java' 'php' 'scala' 'php' 'php' 'php' 'php'\n",
      " 'common lisp' 'php' 'ocaml' 'ocaml' 'common lisp' 'python' 'python'\n",
      " 'common lisp' 'python' 'common lisp']\n"
     ]
    }
   ],
   "source": [
    "print(tree_pipe.score(testy_X, testy_y))\n",
    "print(tree_pipe.predict(testy_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0625\n",
      "['clojure' 'javascript' 'javascript' 'ruby' 'ruby' 'ruby' 'ruby' 'c'\n",
      " 'python' 'ruby' 'javascript' 'python' 'python' 'scheme' 'c#' 'c#' 'ruby'\n",
      " 'java' 'c' 'javascript' 'javascript' 'python' 'javascript' 'javascript'\n",
      " 'ocaml' 'ruby' 'ruby' 'python' 'python' 'javascript' 'c#' 'javascript']\n"
     ]
    }
   ],
   "source": [
    "print(forest_pipe.score(testy_X, testy_y))\n",
    "print(forest_pipe.predict(testy_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03125\n",
      "['clojure' 'javascript' 'scala' 'scala' 'ruby' 'ruby' 'ruby' 'java' 'scala'\n",
      " 'scala' 'scheme' 'clojure' 'scheme' 'scheme' 'c' 'c' 'scala' 'scala' 'php'\n",
      " 'php' 'c' 'php' 'clojure' 'php' 'ocaml' 'ocaml' 'java' 'python' 'python'\n",
      " 'python' 'python' 'javascript']\n"
     ]
    }
   ],
   "source": [
    "print(baye_pipe.score(testy_X, testy_y))\n",
    "print(baye_pipe.predict(testy_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clojure', 'clojure', 'clojure', 'clojure', 'python', 'python', 'python', 'python', 'javascript', 'javascript', 'javascript', 'javascript', 'ruby', 'ruby', 'ruby', 'haskell', 'haskell', 'haskell', 'scheme', 'scheme', 'scheme', 'java', 'java', 'scala', 'scala', 'tcl', 'tcl', 'php', 'php', 'php', 'ocaml', 'ocaml']\n"
     ]
    }
   ],
   "source": [
    "print(testy_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Your Own\n",
    "I used several methods to try to improve the classifier, but it's still not very good. First, I built a custom featurizer using the following functions. I ended up writing a function that takes a regular expression so that I could try different things quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def caps_to_non(text):\n",
    "    cap_letters = re.findall(r'[A-Z]', text)\n",
    "    non_caps = re.findall(r'[a-z]', text)\n",
    "    return len(cap_letters) / len(non_caps)\n",
    "    \n",
    "    \n",
    "def percent_occurence_of_parenthesis(text):\n",
    "    pars = re.findall(r'\\(|\\)', text)\n",
    "    return len(pars) / len(text)\n",
    "\n",
    "\n",
    "def percent_occurence_of_curly(text):\n",
    "    curls = re.findall(r'\\{|\\}', text)\n",
    "    return len(curls) / len(text)\n",
    "\n",
    "\n",
    "def percent_occurence_of_space(text):\n",
    "    spaces = re.findall(r'\\s', text)\n",
    "    return len(spaces) / len(text)\n",
    "\n",
    "    \n",
    "def occurence_of_this_pattern(reg_ex):\n",
    "    \n",
    "    def feature_fn(text):\n",
    "        occ = re.findall(r'{}'.format(reg_ex), text)\n",
    "        return len(occ)\n",
    "\n",
    "    return feature_fn\n",
    "\n",
    "\n",
    "class FunctionFeaturizer(TransformerMixin):\n",
    "    def __init__(self, *featurizers):\n",
    "        self.featurizers = featurizers\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        fvs = []\n",
    "        for text in X:\n",
    "            fv = [f(text) for f in self.featurizers]\n",
    "            fvs.append(fv)\n",
    "        return np.array(fvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After instantiating my featurizer class, I combined it with the CountVectorizer using the sklearn class FeatureUnion. I passed a regular expression to the count vectorizer that tokenizes words, all kinds of white space, and different punctuation. I am using the decision tree classifier, which scored highest in my previous trials, in addition to the linear support vector classifier. Using the TfidfTransformer seems to make the score worse.<br>\n",
    "<br>\n",
    "Without random state argurments, the resulting classifier predicts correctly anywhere from 3.5% to 15.6% of the time, but usually hits between 9% - 12.5%. I don't have any other ideas for how to improve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kathrynjackson/Code/homework/programming-language-classifier/.direnv/python-3.5.1/lib/python3.5/site-packages/sklearn/utils/__init__.py:93: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.954751131222\n",
      "0.125\n",
      "['clojure' 'javascript' 'scala' 'ruby' 'ruby' 'ruby' 'javascript'\n",
      " 'common lisp' 'javascript' 'javascript' 'javascript' 'scala' 'javascript'\n",
      " 'ocaml' 'javascript' 'javascript' 'scala' 'scala' 'php' 'ruby' 'php'\n",
      " 'ruby' 'ruby' 'php' 'ocaml' 'javascript' 'javascript' 'javascript' 'ruby'\n",
      " 'javascript' 'ruby' 'javascript']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kathrynjackson/Code/homework/programming-language-classifier/.direnv/python-3.5.1/lib/python3.5/site-packages/sklearn/utils/__init__.py:93: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/kathrynjackson/Code/homework/programming-language-classifier/.direnv/python-3.5.1/lib/python3.5/site-packages/sklearn/utils/__init__.py:93: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/kathrynjackson/Code/homework/programming-language-classifier/.direnv/python-3.5.1/lib/python3.5/site-packages/sklearn/utils/__init__.py:93: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "featurizer = FunctionFeaturizer(caps_to_non,\n",
    "                                percent_occurence_of_parenthesis,\n",
    "                                percent_occurence_of_curly,\n",
    "                                percent_occurence_of_space,\n",
    "                                occurence_of_this_pattern('&\\w'),\n",
    "                                occurence_of_this_pattern('\\$\\w'),\n",
    "                                occurence_of_this_pattern('[A-Za-z]+[A-Z]'))\n",
    "\n",
    "cv = CountVectorizer(token_pattern=r'[a-zA-Z]{2,}|\\s|[^\\w\\d\\s]', lowercase=False)\n",
    "\n",
    "feature_extractors = FeatureUnion([('my featurizer', featurizer), ('cv', cv)])\n",
    "\n",
    "my_classifier = Pipeline([\n",
    "                    ('featurizer', feature_extractors),\n",
    "#                     ('transformer', TfidfTransformer()),\n",
    "                    ('classifier', DecisionTreeClassifier(criterion='entropy', min_samples_split=1, random_state=1067)),\n",
    "                    ('linsvc', LinearSVC(random_state=13)),\n",
    "                    ])\n",
    "\n",
    "my_classifier.fit(X_train, y_train)\n",
    "my_classifier.named_steps['featurizer'].transform(X_train)\n",
    "print(my_classifier.score(X_test, y_test))\n",
    "\n",
    "print(my_classifier.score(testy_X, testy_y))\n",
    "print(my_classifier.predict(testy_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clojure', 'clojure', 'clojure', 'clojure', 'python', 'python', 'python', 'python', 'javascript', 'javascript', 'javascript', 'javascript', 'ruby', 'ruby', 'ruby', 'haskell', 'haskell', 'haskell', 'scheme', 'scheme', 'scheme', 'java', 'java', 'scala', 'scala', 'tcl', 'tcl', 'php', 'php', 'php', 'ocaml', 'ocaml']\n"
     ]
    }
   ],
   "source": [
    "print(testy_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kathrynjackson/Code/homework/programming-language-classifier/.direnv/python-3.5.1/lib/python3.5/site-packages/sklearn/utils/__init__.py:93: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/kathrynjackson/Code/homework/programming-language-classifier/.direnv/python-3.5.1/lib/python3.5/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/kathrynjackson/Code/homework/programming-language-classifier/.direnv/python-3.5.1/lib/python3.5/site-packages/sklearn/metrics/classification.py:1076: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    clojure       0.25      1.00      0.40         1\n",
      "common lisp       0.00      0.00      0.00         1\n",
      "    haskell       0.00      0.00      0.00         0\n",
      "       java       0.00      0.00      0.00         0\n",
      " javascript       0.75      0.23      0.35        13\n",
      "      ocaml       0.00      0.00      0.00         2\n",
      "        php       0.00      0.00      0.00         3\n",
      "     python       0.00      0.00      0.00         0\n",
      "       ruby       0.00      0.00      0.00         8\n",
      "      scala       0.00      0.00      0.00         4\n",
      "     scheme       0.00      0.00      0.00         0\n",
      "        tcl       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.31      0.12      0.16        32\n",
      "\n",
      "[[1 0 0 0 1 0 0 0 1 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 2 0 0]\n",
      " [0 0 0 0 0 0 0 0 2 0 0 0]\n",
      " [0 0 0 0 3 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 1 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 2 0 0 0 1 0 0 0]\n",
      " [0 1 0 0 1 0 0 0 2 0 0 0]\n",
      " [0 0 0 0 2 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 2 0 1 0 0 0]\n",
      " [0 0 0 0 2 0 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kathrynjackson/Code/homework/programming-language-classifier/.direnv/python-3.5.1/lib/python3.5/site-packages/sklearn/utils/__init__.py:93: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(my_classifier.predict(testy_X), testy_y))\n",
    "print(confusion_matrix(testy_y, my_classifier.predict(testy_X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The commented code is full of unsuccessful attempts to modify the CountVectorizer. I tried passing my own specific vocabulary. I tried different regular expressions. I tried analizing 2 and 3 character n-grams rather than words. None of these methods made a significant difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# my_vocab = ['function', '{', '}', '\\n', '\\t', ':', ';', 'def', ',', '->',\n",
    "#             '(', ')', 'call', 'lambda', 'set', '@', '>', '<', '.', '[',\n",
    "#             ']', 'var', 'elif', 'else', 'else if', 'then', 'in',\n",
    "#             'switch', 'IfTrue', 'IfFalse', 'unless', 'not', 'elsif',\n",
    "#             'given', 'end', 'match', '(if', '(otherwise', 'progn', 'begin',\n",
    "#             'cond', 'then begin', 'with', 'when', 'foreach', 'for each',\n",
    "#             'for_each', 'for (', '$i++', '$i', '$', 'do', 'until', 'loop',\n",
    "#             'let loop', 'for-each', 'done', '.iter', 'catch', 'except',\n",
    "#             'longjmp', 'setjmp', 'finally', 'throw', 'die', 'eval', '$@',\n",
    "#             'rescue', 'ensure', 'handler-', 'check-', 'guard', 'try:',\n",
    "#             'catchError', 'last', 'break', 'return-from',\n",
    "#             'loop-finish', 'go', 'goto', 'next', 'func', 'void', 'int main',\n",
    "#             'main', 'public', 'defun', 'setf', 'define', '&', '*', '/',\n",
    "#             'require', ' = ', 'import', '__init__']\n",
    "# cv = CountVectorizer(vocabulary=my_vocab)\n",
    "\n",
    "# cv = CountVectorizer(token_pattern=r'[a-zA-Z]{2,}|\\s|[^\\w\\d\\s]', lowercase=False)\n",
    "# cv = CountVectorizer(token_pattern=r'[a-zA-Z]{2,}|[^\\w\\d\\s]+')\n",
    "\n",
    "# cv = CountVectorizer(analyzer='char', ngram_range=(2,3))\n",
    "\n",
    "# cv = CountVectorizer(lowercase=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def language_guesser(snippet):\n",
    "    return my_classifier.predict([snippet])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kathrynjackson/Code/homework/programming-language-classifier/.direnv/python-3.5.1/lib/python3.5/site-packages/sklearn/utils/__init__.py:93: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['javascript'], \n",
       "      dtype='<U11')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_guesser('''def an_imaginary_function:\\n    return dict = {'a': 'B'}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
